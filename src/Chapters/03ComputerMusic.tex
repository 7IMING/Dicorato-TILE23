% !TEX TS-program = pdflatex
% !TEX root = ../tesi.tex

%************************************************
\chapter{LA COMPUTER MUSIC PER I VIDEO-GAMES}
\label{chp:La Computer Music per i Video-Games}
%************************************************
La computer music è l'applicazione della tecnologia informatica nella composizione musicale, per aiutare i compositori umani a creare nuova musica o per avere computer che creano musica in modo indipendente, come con i programmi di composizione algoritmica. \\
Include la teoria e l'applicazione di tecnologie software per computer nuove ed esistenti e aspetti di base della musica, come la sintesi del suono, l'elaborazione del segnale digitale, il sound design, la diffusione sonora, l'acustica, l'ingegneria elettrica e la psicoacustica.\\
Il campo della computer music può far risalire le sue radici alle origini della musica elettronica e ai primi esperimenti e innovazioni con strumenti elettronici a cavallo del 20 ° secolo.\\
I videogiochi emersero come forma di intrattenimento popolare lungo gli ultimi anni settanta (il periodo delle console di seconda generazione), e la loro musica era registrata su musicassetta o dischi in vinile.\\
Un altro metodo più economico per realizzarla consisteva nell'adoperare un chip, che sostituiva gli impulsi elettrici del codice di un computer a onde sonore analogiche.\\
A partire dal 1980, alcuni videogiochi iniziarono ad adoperare, oltre ai sintetizzatori ed ai computer, apparecchiature digitali e campionamenti per fare musica oggi riconosciuta come chiptune.\\
Mentre le console casalinghe si avvicinavano alla quarta generazione (o era dei 16-bit), quell'approccio ibrido continuò ad essere usato.
Nel 1988 le console offrivano, fra le altre innovazioni, una grafica avanzata ed una sintesi sonora perfezionata rispetto a quelle dei supporti precedenti.\\
 A partire dagli anni novanta, la musica per videogiochi iniziò a presentare sonorità realizzate con strumenti musicali veri e propri.\\
 Questo fu dovuto all'evoluzione dei computer che divennero, grazie alle capacità di contenimento dei dati dei giochi sempre più rapidi e potenti.
 Successivamente arrivò il supporto da 64 bit composto da due coprocessori di 32 bit ciascuno, seguito dal riverbero, per arrivare poi all'invenzione di IMUSE, un motore di gioco che controlla la musica del videogioco in tempo reale.
 Sino all'arrivo della musica su licenza che prevedeva l'introduzione di composizione già esistenti di musiche hip-hop, rap, pop, rock e così via.\\
 Oggi esistono due categorie: Musiche originali e Musica con licenza.

 \subsection*{La Musica Generativa}
 La mia aggiunta personale, non presente attualmente nella storia musicale dei videogiochi, è quella di un ramo della Computer Music,
 ovvero la Musica Generativa.\\
 La musica generativa è un termine reso popolare da Brian Eno per descrivere la musica che è sempre diversa e mutevole e che è creata da un sistema.\\
 Ci sono quattro prospettive primarie sulla musica generativa (Wooller, R. et al., 2005) (riprodotte con permesso):

 \subsubsection*{Linguistico/Strutturale}

 Musica composta da teorie analitiche così esplicite da poter generare materiale strutturalmente coerente (Loy e Abbott 1985; Cope 1991).
 Questa prospettiva ha le sue radici nelle grammatiche generative del linguaggio (Chomsky 1956) e della musica (Lerdahl e Jackendoff 1983), che generano materiale con una struttura ad albero ricorsiva.
 
\subsubsection*{Interattivo/comportamentale}
Musica generata da un componente di sistema che non ha input musicali distinguibili. Cioè, "non trasformativo" (Rowe 1991; Lippe 1997:34; Winkler 1998).
 Il software Wotja di Intermorphic e il software Koan di SSEYO utilizzato da Brian Eno per creare Generative Music 1, sono entrambi esempi di questo approccio.

 \subsubsection*{Creativo/procedurale}
 Musica generata da processi progettati e/o avviati dal compositore. It's Gonna Rain di Steve Reich e In C di Terry Riley ne sono esempi (Eno 1996).

 \subsubsection*{Biologico/emergente}
 Musica non deterministica (Biles 2002), o musica che non può essere ripetuta, ad esempio, i normali campanelli a vento (Dorin 2001). Questa prospettiva proviene dal più ampio movimento dell'arte generativa.\\
 Questo ruota attorno all'idea che la musica, o i suoni, possano essere "generati" da un musicista "coltivando" parametri all'interno di un'ecologia, in modo tale che l'ecologia produrrà perpetuamente variazioni diverse in base ai parametri e agli algoritmi utilizzati.\\ 
 Un esempio di questa tecnica è Viral symphOny di Joseph Nechvatal: una sinfonia collaborativa di musica noise elettronica creata tra gli anni 2006 e 2008 utilizzando un software di vita artificiale personalizzato basato su un modello virale.

\section{Materiali}
La composizione che viene adattata al contesto audio-video 3D di Unity è stata realizzata mediante 
l'uso dell'ambiente di calcolo del Mathematica,
il quale sfrutta il linguaggio di programmazione interpretato Wolfram per generare suoni riprodotti da Csound,
che è un altro linguaggio sviluppato in C.\\
Tramite questo procedimento è possibile riprodurre varie tipologie di suoni e sintesi.
All'interno di questo brano sono presenti: Sintesi additiva, sintesi sottrattiva, sintesi granulare con l'ausilio del campionatore.\\

\subsection*{Mathematica}

Pertanto, dispongo come esempio uno dei codici utilizzati per dare atto pratico della produzione nel Mathematica, nel quale principalmente
possono essere presenti diversi parametri compositivi come: il numero degli strumenti, il ritmo, la durata, la dinamica, l'ampiezza, la frequenza, la forma d'onda,
l'attacco percentuale, il rateo di lettura, la spazializzazione e così via.

\subsubsection*{Sintesi Additiva}

La sintesi additiva è una tecnica di sintesi sonora utilizzata nella musica elettronica che crea timbriche,
 quindi forme d'onda comunque complesse, sommando insieme singole onde, generalmente sinusoidali.

\begin{lstlisting}
    codice[additivaUnSuono] := (
        nomeOrchestra = "additiva.csd";
        nomeCSD = "mathAdditiva.csd";
        
        colonneCsound = Range[7];
        colonneProcessing = {};
        (*Parameter Field Number*)
        numPFV = Union[colonneCsound, colonneProcessing] ;
        mascheraPFV = Table[{}, {numPFV}];
        
        clcLstPFV := Association @@ {
           (*1*)
           1 :> {1},
           (*2*)
           2 :> {.5},
           (*3*)
           3 :> {2},
           (*4*)
           4 :> {3000}(*iamp*),
           (*5*)  (*freq*)
           5 :> RandomSample[Range[.5, 100, .2]],
           (*6*)
           6 :> {1}(*ifn*),
           (*7*)
           7 :> {.9}(*attacco perc*)});
     
     (* inizializzazione Tempi *)
     attaccoIniziale = 0;
     durataSezione = 70;
    \end{lstlisting}

    \subsubsection*{Sintesi Granulare}

    La sintesi granulare è un metodo base della sintesi del suono che opera con degli elementi acustici elementari chiamati microsound o grani.

\begin{lstlisting}
    clcLstPFV := Association @@ {
     1 :> {1},
     2 :> p02,
     3 :> p03,
     (*iamp;percentuale[0,n]*)
     4 :> p04,
     (*ifilcod*)
     5 :> RandomSample[nomiFile],
     (*iratio*)
     6 :> p06,
     (*iskiptimePerc*)
     7 :> p07,
     (* attacco perc *)
     8 :> p08,
     (* ispaz: left=0 *)
     9 :> {.5}
     });

(*Tutte le funzioni sono date in tempo percentuale, che va da 
attaccoIniziale + {0 , durataSezione}*)
(* inizializzazione Tempi *)

(*parametro compositivo: 1*)
attaccoIniziale = 0;

(*parametro compositivo: 2*)
durataSezione = 30;

(*parametro compositivo: 3*)
campioni = Dataset[{
    <|"nomeFile" -> "\"uccelli.wav\"", "durataFile" -> 2.756|>,
    <|"nomeFile" -> "\"bisbigli.wav\"", "durataFile" -> 5.593|>,
    <|"nomeFile" -> "\"vocemaschile.wav\"", "durataFile" -> 3.668|>}];

\end{lstlisting}

\subsubsection*{Sintesi Sottrattiva}

Per sintesi sottrattiva ci si riferisce ad un modello di sintesi sonora utilizzata nella musica elettronica nella quale una sorgente sonora (oscillatori o parziali) ricca di armoniche,
 viene filtrata da un punto di vista spettrale "sottraendo" o modulando da essa bande di frequenze o singole parziali.

\begin{lstlisting}
    clcLstPFV := Association @@ {
     (*1*)(*numero strumento*)
     1 :> {7},
     (*2*)(*attack time*)
     (*con colpo per ogni inizio lista*)
     2 :> {Table[0, {2^RandomInteger[{0, 3}]}], 
        RandomSample[
         Flatten[Table[2^-(i - 1), {i, 1, 3}, {1/2^-(i - 1)}], 1]]}*2,
     
     (*3*)(*durata*)
     3 :> 
      RandomSample[
        Flatten[Table[2^-(i - 1), {i, 1, 6}, {1/2^-(i - 1)}], 1]]*16,
     
     (*{Range[1,RandomInteger[{5,10}],1],Range[RandomInteger[{5,10}],
     1,-1]}*.05,*)
     (*4*)(*iamp*)
     4 :> (RandomSample[
          Flatten[Table[2^-(i - 1), {i, 1, 6}, {1/2^-(i - 1)}], 
           1]]*10000 // N),
     (*5*)(*i freq cut*)
     (*{55,RandomReal[{55,8000},3],8000},*)
     5 :> (modulo = 2;
       numSemitoni = 12;
       freqBase = 880;
       scalaMagg = {0, 2, 4, 5, 7, 9, 11};
       scalaMinArm = {0, 2, 3, 5, 7, 8, 11};
       scalaPentatonica = {0, 2, 5, 7, 9};
       TriadeMaggiore = {0, 4, 7};
       Armonici = intervalToSemitone[Range[1, 32]];
       
       scala = scalaMinArm;
       modulo^
          RandomSample[(Table[12 i + scala, {i, -1, 1}]/numSemitoni) //
             Flatten]*freqBase // N),
     (*6*)(*iq*)
     6 :> {10^RandomReal[{-.25, 2}]},
     (*RandomChoice[Range[20],40]*)
     (*7*)(*attacco perc*)
     7 :> {Subdivide[.3, .6, 19]^3, Subdivide[.6, .3, 11]^3},
     (*8*)(*iLeft*)
     8 :> {Subdivide[0, 1, 11]^3, Subdivide[1, 0, 23]^3}
     });

(* inizializzazione Tempi *)
attaccoIniziale = 0;
durataSezione = 60;
\end{lstlisting}

\section{Implementazione in Ambisonics}
Per l'Implementazione in Ambisonics del tracce del brano, che si chiama "Absence of light", ho utilizzato la Suite dei Plug-in dell'IEM.
Il montaggio e il lavoro in ambito sonoro è stato eseguito sulla DAW Reaper.\\
In particolare, sono stati usati due plug-in: Lo StereoEncoder e il BinauralDecoder; in quanto i videogiochi possono raggiungere i massimi
livelli di immersività solo tramite cuffie, perchè ci permettono di simulare al meglio i suoni ambientali all'interno del gioco, 
soprattutto nei contesti più competitivi dove il minimo dettaglio conta.

\subsubsection*{StereoEncoder}

Lo usiamo per codificare segnali audio mono o stereo nel dominio Ambisonic.
Nell'angolo in alto a destra è possibile impostare l'ordine Ambisonic desiderato e la normalizzazione.
Si usano i cursori Azimuth, Elevazione e Roll per eseguire una panoramica della sorgente.\\
Con il cursore Larghezza è possibile separare i due canali di ingresso.
Inoltre, c'è un ingresso di quaternione che puoi usare come alternativa all'azimut e all'elevazione, ad esempio per i dati di orientamento degli inseguitori (di testa).

\subsubsection*{BinauralDecoder}

Il decodificatore binaurale manda il segnale di ingresso Ambisonic a un segnale di cuffie binaurali utilizzando l'approccio MagLS proposto.
 Gli HRTF utilizzati provengono dalla testa fittizia Neumann KU 100. 
 Inoltre, è possibile applicare le equalizzazioni delle cuffie dalle misurazioni di Benjamin Bernschütz et. al..\\
A differenza dei decodificatori binaurali convenzionali, questo decodificatore binaurale non utilizza altoparlanti virtuali, ma converte i segnali Ambisonic direttamente in segnali binaurali per cuffie,
 con l'aiuto di HRTF pre-elaborati.\\
 Vengono elaborati in modo che la risposta in frequenza originale degli HRTF sia mantenuta nel miglior modo possibile, quando utilizzati con Ambisonics.